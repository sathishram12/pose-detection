{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47b1868f-5f02-4627-bbcd-d12ae45e822c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 17:22:14.788155: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-30 17:22:14.929241: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-30 17:22:15.728734: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sathish/miniconda3/envs/tf/lib/python3.9/site-packages/cv2/../../lib64:/opt/ros/humble/opt/rviz_ogre_vendor/lib:/opt/ros/humble/lib/x86_64-linux-gnu:/opt/ros/humble/lib:/home/sathish/miniconda3/envs/tf/lib/\n",
      "2023-03-30 17:22:15.728833: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sathish/miniconda3/envs/tf/lib/python3.9/site-packages/cv2/../../lib64:/opt/ros/humble/opt/rviz_ogre_vendor/lib:/opt/ros/humble/lib/x86_64-linux-gnu:/opt/ros/humble/lib:/home/sathish/miniconda3/envs/tf/lib/\n",
      "2023-03-30 17:22:15.728840: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "from tensorpack.dataflow import MultiProcessMapDataZMQ,MultiProcessMapAndBatchDataZMQ, TestDataSpeed\n",
    "from tensorpack.dataflow.common import MapData\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from dataset.augmentors import CropAug, FlipAug, ScaleAug, RotateAug, ResizeAug\n",
    "from dataset.base_dataflow import CocoDataFlow, JointsLoader\n",
    "from dataset.dataflow_steps import create_all_mask, augment, read_img, apply_mask, gen_mask\n",
    "from dataset.label_maps import PredictionData\n",
    "\n",
    "def build_sample(components):\n",
    "    \"\"\"\n",
    "    Builds a sample for a model.\n",
    "\n",
    "    :param components: components\n",
    "    :return: list of final components of a sample.\n",
    "    \"\"\"\n",
    "    pred_data = PredictionData(components[13])\n",
    "\n",
    "    return [components[10], pred_data.kp_heatmaps(),\n",
    "            pred_data.compute_short_offsets(), pred_data.compute_mid_offsets()]\n",
    "\n",
    "\n",
    "def get_dataflow(annot_path, img_dir, strict, x_size = 224):\n",
    "    \"\"\"\n",
    "    This function initializes the tensorpack dataflow and serves generator\n",
    "    for training operation.\n",
    "\n",
    "    :param annot_path: path to the annotation file\n",
    "    :param img_dir: path to the images\n",
    "    :return: dataflow object\n",
    "    \"\"\"\n",
    "    coco_crop_size = 368\n",
    "\n",
    "    # configure augmentors\n",
    "\n",
    "    augmentors = [\n",
    "        ScaleAug(scale_min=0.8,\n",
    "                 scale_max=2.0,\n",
    "                 target_dist=0.8,\n",
    "                 interp=cv2.INTER_CUBIC),\n",
    "\n",
    "        RotateAug(rotate_max_deg=30,\n",
    "                  interp=cv2.INTER_CUBIC,\n",
    "                  border=cv2.BORDER_CONSTANT,\n",
    "                  border_value=(128, 128, 128), mask_border_val=1),\n",
    "\n",
    "        #CropAug(coco_crop_size, coco_crop_size, center_perterb_max=40, border_value=128,\n",
    "        #        mask_border_val=1),\n",
    "\n",
    "        FlipAug(num_parts=17, prob=0.5),\n",
    "\n",
    "        ResizeAug(x_size[1], x_size[0])\n",
    "\n",
    "    ]\n",
    "\n",
    "    # prepare augment function\n",
    "\n",
    "    augment_func = functools.partial(augment,\n",
    "                                     augmentors=augmentors)\n",
    "\n",
    "    # prepare building sample function\n",
    "\n",
    "    build_sample_func = functools.partial(build_sample)\n",
    "\n",
    "    df = CocoDataFlow((coco_crop_size, coco_crop_size), annot_path, img_dir)\n",
    "    df.prepare()\n",
    "    size = df.size()\n",
    "    df = MapData(df, read_img)\n",
    "    df = MapData(df, augment_func)\n",
    "    df = MultiProcessMapAndBatchDataZMQ(df, num_proc=4, map_func=build_sample_func,batch_size=4)\n",
    "\n",
    "    return df, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3ca5e2-699b-4bbf-a821-e529657dfa09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.46s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading image annot 0/5000\n",
      "Loading image annot 2000/5000\n",
      "Loading image annot 4000/5000\n",
      "\u001b[32m[0330 17:22:21 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Starting a process with 'fork' method is not safe and may consume unnecessary extra CPU memory. Use 'forkserver/spawn' method (available after Py3.4) instead if you run into any issues. See https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|#4                                                                                                                 |61/5000[01:33<2:06:01, 0.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m img_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(curr_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/coco2017/val2017/\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      6\u001b[0m df1, size1 \u001b[38;5;241m=\u001b[39m get_dataflow(annot_path, img_dir, \u001b[38;5;28;01mFalse\u001b[39;00m, x_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m353\u001b[39m,\u001b[38;5;241m281\u001b[39m))\n\u001b[0;32m----> 7\u001b[0m \u001b[43mTestDataSpeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorpack/dataflow/common.py:63\u001b[0m, in \u001b[0;36mTestDataSpeed.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# add smoothing for speed benchmark\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_size,\n\u001b[1;32m     62\u001b[0m               leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, dp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(itr):\n\u001b[1;32m     64\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorpack/dataflow/parallel_map.py:435\u001b[0m, in \u001b[0;36mMultiProcessMapAndBatchDataZMQ.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_guard, _zmq_catch_error(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorpack/utils/serialize.py:39\u001b[0m, in \u001b[0;36mloads_msgpack\u001b[0;34m(buf)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    buf: the output of `dumps`.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Since 0.6, the default max size was set to 1MB.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# We change it to approximately 1G.\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmsgpack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmax_bin_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_MSGPACK_LEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmax_array_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_MSGPACK_LEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmax_map_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_MSGPACK_LEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmax_str_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_MSGPACK_LEN\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/msgpack_numpy.py:287\u001b[0m, in \u001b[0;36munpackb\u001b[0;34m(packed, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m object_hook \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject_hook\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    286\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject_hook\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(decode, chain\u001b[38;5;241m=\u001b[39mobject_hook)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_unpackb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mmsgpack/_unpacker.pyx:194\u001b[0m, in \u001b[0;36mmsgpack._cmsgpack.unpackb\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/msgpack_numpy.py:89\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(obj, chain)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(obj, chain\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    Decoder for deserializing numpy data types.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnd\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m obj:\n\u001b[1;32m     91\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m obj[\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnd\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m                 \u001b[38;5;66;03m# Check if b'kind' is in obj to enable decoding of data\u001b[39;00m\n\u001b[1;32m     94\u001b[0m                 \u001b[38;5;66;03m# serialized with older versions (#20) or data\u001b[39;00m\n\u001b[1;32m     95\u001b[0m                 \u001b[38;5;66;03m# that had dtype == 'O' (#46):\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "curr_dir = os.path.dirname(\"__file__\")\n",
    "annot_path = os.path.join(curr_dir, '../../data/coco2017/annotations/person_keypoints_val2017.json')\n",
    "img_dir = os.path.abspath(os.path.join(curr_dir, '../../data/coco2017/val2017/'))\n",
    "\n",
    "df1, size1 = get_dataflow(annot_path, img_dir, False, x_size=(353,281))\n",
    "TestDataSpeed(df1).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488951b-5517-438d-b100-e469f17bbede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
